{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "base_url = 'https://www.imdb.com'\n",
    "chrome_driver_path = r\"D:\\NMKHDL\\DATA-SCIENCE\\data-collection\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_shows(driver, pause_time = 1, max_failures = 3):\n",
    "    scroll_count = 0\n",
    "    fail_count = 0\n",
    "    while fail_count < max_failures:\n",
    "        try:\n",
    "            button = driver.find_element(By.XPATH, '//button[contains(@class, \"ipc-see-more__button\")]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            scroll_count += 1\n",
    "            time.sleep(pause_time)\n",
    "            fail_count = 0\n",
    "        except exceptions.NoSuchElementException:\n",
    "            fail_count += 1\n",
    "            time.sleep(pause_time)\n",
    "        except exceptions.ElementClickInterceptedException:\n",
    "            print(\"Scroll or element interaction issue. Retrying...\")\n",
    "            time.sleep(pause_time)\n",
    "    return scroll_count\n",
    "\n",
    "def get_show_links(driver):\n",
    "    try:\n",
    "        links = driver.find_elements(By.XPATH, '//li[contains(@class, \"ipc-metadata-list-summary-item\")]')\n",
    "        return [link.find_element(By.TAG_NAME, 'a').get_attribute('href') for link in links]\n",
    "    except exceptions.NoSuchElementException:\n",
    "        print(\"No show links found.\")\n",
    "        return []\n",
    "    \n",
    "def clean_links(links):\n",
    "    return [link.split('?')[0] for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scrolls: 80\n",
      "Total links: 3980\n",
      "Links saved to imdb_links.txt\n"
     ]
    }
   ],
   "source": [
    "service = Service(chrome_driver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "url = f'{base_url}/search/title/?title_type=tv_series,tv_miniseries&num_votes=5000,&sort=user_rating,desc'\n",
    "driver.get(url)\n",
    "total_scrolls = load_all_shows(driver)\n",
    "print(\"Total scrolls:\", total_scrolls)\n",
    "\n",
    "links = get_show_links(driver)\n",
    "clean_links_list = clean_links(links)\n",
    "print(\"Total links:\", len(clean_links_list))\n",
    "\n",
    "filename = 'imdb_links.txt'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(\"\\n\".join(clean_links_list))\n",
    "print(\"Links saved to\", filename)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Tập Làm Người Xấu\n",
      "Original Title: uOriginal title: Breaking BadTV Series2008–2013C1845m\n",
      "Series Type: TV Series\n",
      "Release Year: 2008–2013\n",
      "Certificate: C18\n",
      "Runtime: 45m\n",
      "IMDb Rating: 9.5\n",
      "Number of Ratings: 2.3M\n",
      "Popularity: 25\n",
      "Popularity Delta: -2\n",
      "Genres: ['Desert Adventure', 'Drug Crime', 'Epic', 'Psychological Drama', 'Psychological Thriller', 'Tragedy', 'Crime', 'Drama', 'Thriller']\n",
      "Creators: ['Vince Gilligan']\n",
      "Stars: ['Bryan Cranston', 'Aaron Paul', 'Anna Gunn']\n",
      "User Reviews: 5.1K\n",
      "Critic Reviews: 176\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.imdb.com/title/tt0903747/'\n",
    "\n",
    "def load_user_agents(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        return [line.strip() for line in file.readlines()]\n",
    "    \n",
    "user_agents = load_user_agents('user_agents.txt')\n",
    "\n",
    "response = requests.get(url, headers={'User-Agent': random.choice(user_agents)})\n",
    "response.raise_for_status()\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "title_div = soup.select_one('.sc-70a366cc-0.bxYZmb')\n",
    "title = title_div.find('h1', {'data-testid': 'hero__pageTitle'}).get_text(strip=True)\n",
    "original_title = title_div.get_text(strip=True)[16:] if title_div.find('div', class_='sc-ec65ba05-1 fUCCIx') else None\n",
    "print(\"Title:\", title)\n",
    "print(\"Original Title:\", original_title)\n",
    "\n",
    "details_list = title_div.find('ul', class_='ipc-inline-list ipc-inline-list--show-dividers sc-ec65ba05-2 joVhBE baseAlt')\n",
    "details_list = details_list.find_all('li')\n",
    "series_type = details_list[0].get_text(strip=True) if len(details_list) > 0 else None\n",
    "release_year = details_list[1].get_text(strip=True) if len(details_list) > 1 else None\n",
    "certificate = details_list[2].get_text(strip=True) if len(details_list) > 2 else None\n",
    "runtime = details_list[3].get_text(strip=True) if len(details_list) > 3 else None\n",
    "print(f\"Series Type: {series_type}\")\n",
    "print(f\"Release Year: {release_year}\")\n",
    "print(f\"Certificate: {certificate}\")\n",
    "print(f\"Runtime: {runtime}\")\n",
    "\n",
    "rating_div = soup.find('div', class_='sc-3a4309f8-1 dOjKRs')\n",
    "rating = rating_div.find('span', class_='sc-d541859f-1 imUuxf').get_text(strip=True)\n",
    "num_ratings = rating_div.find('div', class_='sc-d541859f-3 dwhNqC').get_text(strip=True)\n",
    "popularity_score = rating_div.find('div', class_='sc-39d285cf-1 dxqvqi')\n",
    "popularity_score = popularity_score.get_text(strip=True) if popularity_score else None\n",
    "popularity_delta = rating_div.find('div', class_='sc-39d285cf-2 bHiRqw')\n",
    "popularity_delta = popularity_delta.get_text(strip=True) if popularity_delta else None\n",
    "if rating_div.find('svg', class_='ipc-icon--arrow-drop-up'):\n",
    "    popularity_delta = f\"+{popularity_delta}\"\n",
    "elif rating_div.find('svg', class_='ipc-icon--arrow-drop-down'):\n",
    "    popularity_delta = f\"-{popularity_delta}\"\n",
    "print(f\"IMDb Rating: {rating}\")\n",
    "print(f\"Number of Ratings: {num_ratings}\")\n",
    "print(f\"Popularity: {popularity_score}\")\n",
    "print(f\"Popularity Delta: {popularity_delta}\")\n",
    "\n",
    "description_div = soup.select_one('.sc-9a2a0028-10.iUfJXd')\n",
    "genres_text = description_div.find('div', class_='ipc-chip-list__scroller')\n",
    "genres = [genre.get_text(strip=True) for genre in genres_text.find_all('span')]\n",
    "creators_text = description_div.find('div', class_='ipc-metadata-list-item__content-container')\n",
    "creators = [creator.get_text(strip=True) for creator in creators_text.find_all('a')]\n",
    "stars_text = description_div.find_all('div', class_='ipc-metadata-list-item__content-container')[1]\n",
    "stars = [star.get_text(strip=True) for star in stars_text.find_all('a')]\n",
    "print(\"Genres:\", genres)\n",
    "print(\"Creators:\", creators)\n",
    "print(\"Stars:\", stars)\n",
    "\n",
    "reviews_div = soup.select_one('.sc-9a2a0028-11.ketnsO')\n",
    "reviews_list = reviews_div.find('ul', class_='ipc-inline-list sc-b782214c-0 bllRjU baseAlt')\n",
    "user_reviews = reviews_list.find_all('li')[0].find('span', class_='score').get_text(strip=True)\n",
    "critic_reviews = reviews_list.find_all('li')[1].find('span', class_='score').get_text(strip=True)\n",
    "print(\"User Reviews:\", user_reviews)\n",
    "print(\"Critic Reviews:\", critic_reviews)\n",
    "\n",
    "# awards = soup.select_one('.sc-710dd9d1-0.evrEcj')\n",
    "tmp= soup.find('div', class_='ipc-page-content-container')\n",
    "awards = tmp.find('section', class_='ipc-page-section')\n",
    "print(awards)\n",
    "\n",
    "# awards = soup.select_one('.sc-aa5ab255-0.evrEcj').find('span').get_text(strip=True)\n",
    "# print(\"Awards:\", awards)\n",
    "\n",
    "# seasons = soup.select_one('.sc-8592ce7f-4.xDejQ').find('label').get_text(strip=True)\n",
    "# print(\"Seasons:\", seasons)\n",
    "\n",
    "# episodes = soup.select_one('.ipc-title.ipc-title--base').find_all('span')[1].get_text(strip=True)\n",
    "# print(\"Episodes:\", episodes)\n",
    "# details_div = soup.find('div', {'data-testid': 'title-details-section'}).find_all('li')\n",
    "# for detail in details_div:\n",
    "#     tmp = detail.find('li', class_='ipc-inline-list__item')\n",
    "#     print(tmp)\n",
    "\n",
    "# df = pd.DataFrame(tvshows, columns=['Title', 'Years', 'Certification', 'Runtime', 'Rating', 'Number of Votes', 'Emmys', 'Creators', 'Actors', 'Genres', 'Coutries of origins', 'Languages', 'Production companies', 'Link'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
