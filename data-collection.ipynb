{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time, random, re\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section imports the essential Python libraries and modules required for automating web interactions, data extraction, and processing. Each library and module serves a specific purpose:\n",
    "- **Selenium**: (webdriver, Service, WebDriverWait, By, exceptions): A powerful tool for automating web browsers. It enables programmatically interacting with web elements for data scraping or testing purposes. Key functionalities include:\n",
    "    - Automating web browser actions.\n",
    "    - Locating and interacting with elements on a webpage.\n",
    "    - Handling exceptions and timeouts during operations.\n",
    "- **time**: Provides time-related functions to control the execution flow, such as adding delays between automated browser actions to mimic human behavior.\n",
    "- **random**: Useful for generating random numbers, introducing variability in actions like wait times to avoid detection during web scraping.\n",
    "- **re**: A module for working with regular expressions, enabling pattern matching for string processing tasks, such as extracting specific text from webpage content.\n",
    "- **pandas (pd)**: A robust data manipulation library, used here to organize and store collected data in structured formats like DataFrames for easy analysis.\n",
    "- **multiprocessing (Pool, multiprocessing)**: Supports parallel processing to speed up data collection by distributing tasks across multiple CPU cores, making scraping large datasets more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Extract TVShows Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function retrieves product page URLs from a list of web elements. It locates the `<a>` tags within the elements and extracts their `href` attributes.\n",
    "\n",
    "- **Input:** List of product elements.\n",
    "- **Output:** List of product URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(products):\n",
    "    url = []\n",
    "    for p in products:\n",
    "        url.append(p.find_element(By.TAG_NAME, value='a').get_attribute('href'))\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Get TVShows Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function extracts detailed information about a TV show or movie from a given URL using Selenium for web scraping.\n",
    "- **Input:** A URL pointing to the show's details page.\n",
    "- **Output:** A list containing the following details:\n",
    "\n",
    "| **Field**         | **Description**                                                                                     |\n",
    "|--------------------|-----------------------------------------------------------------------------------------------------|\n",
    "| **Title**          | The name of the show.                                                                              |\n",
    "| **Years**          | The years the show was active or released.                                                         |\n",
    "| **Certification**  | The age rating of the show (e.g., PG, R).                                                          |\n",
    "| **Runtime**        | Duration of the show or episodes.                                                                  |\n",
    "| **Rating**         | Audience or critic rating (e.g., IMDb score).                                                      |\n",
    "| **Votes**          | Number of votes contributing to the rating.                                                        |\n",
    "| **Emmys**          | Number of Primetime Emmy awards won.                                                               |\n",
    "| **Creators**       | List of creators associated with the show.                                                         |\n",
    "| **Actors**         | List of main cast members.                                                                         |\n",
    "| **Genres**         | Categories the show falls into, such as drama, comedy, etc.                                        |\n",
    "| **Origins**        | Countries of origin for the show.                                                                  |\n",
    "| **Languages**      | Languages in which the show is available.                                                          |\n",
    "| **Productions**    | Production companies involved in creating the show.                                                |\n",
    "| **URL**            | The original URL used to extract the details (for reference).                                      |\n",
    "\n",
    "**Key Features:**\n",
    "- Utilizes Selenium for DOM interaction and dynamic content loading.\n",
    "- Implements error handling for missing elements using `try-except` blocks.\n",
    "- Extracts multiple fields from different parts of the page:\n",
    "  - Awards, genres, details (e.g., origin, language, production companies).\n",
    "- Incorporates scrolling and waiting for dynamic elements to load fully.\n",
    "\n",
    "**Usage:**\n",
    "This function is suitable for gathering comprehensive metadata about shows for building datasets or conducting detailed analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shows_info(url):\n",
    "    CHROMEDRIVER_PATH = '/usr/local/bin/chromedriver'\n",
    "    service = Service(executable_path=CHROMEDRIVER_PATH)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    driver.get(url)\n",
    "\n",
    "    title = WebDriverWait(driver, 2).until(lambda x: x.find_element(By.CLASS_NAME, 'hero__primary-text')).get_attribute('innerHTML')\n",
    "    try:\n",
    "        years = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/ul/li[2]/a').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        years = pd.NA\n",
    "    try:\n",
    "        certification = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/ul/li[3]/a').text\n",
    "    except exceptions.NoSuchElementException:\n",
    "        certification = pd.NA\n",
    "    try:\n",
    "        runtime = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/ul/li[4]').text   \n",
    "    except exceptions.NoSuchElementException:\n",
    "        runtime = pd.NA\n",
    "    try:\n",
    "        rating = driver.find_element(By.XPATH, '//span[@class=\"sc-d541859f-1 imUuxf\"]').get_attribute('innerHTML')\n",
    "    except exceptions.NoSuchElementException:\n",
    "        rating = pd.NA\n",
    "    try:\n",
    "        votes = driver.find_element(By.XPATH, '//div[@class=\"sc-d541859f-3 dwhNqC\"]').get_attribute('innerHTML')   \n",
    "    except exceptions.NoSuchElementException:\n",
    "        votes = pd.NA\n",
    "    emmys = 0\n",
    "    try:\n",
    "        awards = driver.find_element(By.XPATH, '//li[@data-testid=\"award_information\"]//a').get_attribute('innerHTML')\n",
    "        awards = re.search(r'Won (\\d{1,2}) Primetime Emmy', awards)\n",
    "        emmys = int(awards.group(1)) if awards else 0\n",
    "    except exceptions.NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    creators = []\n",
    "    actors = []\n",
    "    try:\n",
    "        title_cast = driver.find_element(By.XPATH, '//section[@data-testid=\"title-cast\"]')  \n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", title_cast)\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            creator = title_cast.find_element(By.XPATH, './/ul[contains(@class, \"ipc-metadata-list\")]//ul')\n",
    "            for c in creator.find_elements(By.TAG_NAME, 'a'):\n",
    "                creators.append(c.get_attribute('innerHTML'))\n",
    "        except exceptions.NoSuchElementException:\n",
    "            pass\n",
    "        for c in title_cast.find_elements(By.XPATH, './/div[@data-testid=\"title-cast-item\"]'):\n",
    "            try:\n",
    "                actors.append(c.find_element(By.XPATH, './/a[@data-testid=\"title-cast-item__actor\"]').get_attribute('innerHTML'))\n",
    "            except exceptions.NoSuchElementException:\n",
    "                pass\n",
    "    except exceptions.NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    creators = ', '.join(creators) if creators else pd.NA\n",
    "    actors = ', '.join(actors) if actors else pd.NA\n",
    "    for _ in range(5):  \n",
    "        try:\n",
    "            storyline = WebDriverWait(driver, 2).until(lambda x: x.find_element(By.XPATH, '//li[@data-testid=\"storyline-genres\"]'))\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", storyline)\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        except exceptions.TimeoutException:\n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    time.sleep(1)\n",
    "    genres = []\n",
    "    for e in storyline.find_elements(By.TAG_NAME, 'a'):\n",
    "        try:\n",
    "            genres.append(e.get_attribute('innerHTML'))\n",
    "        except exceptions.StaleElementReferenceException:\n",
    "            print(title)\n",
    "    genres = ', '.join(genres) if genres else pd.NA\n",
    "    for _ in range(5):    \n",
    "        try: \n",
    "            details = WebDriverWait(driver, 2).until(lambda x: x.find_element(By.XPATH, '//section[@data-testid=\"Details\"]'))\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", details)\n",
    "            time.sleep(1)  \n",
    "            break\n",
    "        except exceptions.TimeoutException:\n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\") \n",
    "            time.sleep(1)\n",
    "    \n",
    "    origins = []\n",
    "    try:\n",
    "        og = WebDriverWait(details, 2).until(lambda x: x.find_elements(By.XPATH, './/li[@data-testid=\"title-details-origin\"]//ul//a'))\n",
    "        for o in og:\n",
    "            origins.append(o.get_attribute('innerHTML'))\n",
    "    except exceptions.TimeoutException:\n",
    "        pass\n",
    "    origins = ', '.join(origins) if origins else pd.NA\n",
    "\n",
    "    languages = []\n",
    "    try:\n",
    "        lang = WebDriverWait(details, 2).until(lambda x: x.find_elements(By.XPATH, './/li[@data-testid=\"title-details-languages\"]//ul//a'))\n",
    "        for l in lang:\n",
    "            languages.append(l.get_attribute('innerHTML'))\n",
    "    except exceptions.TimeoutException:\n",
    "        pass\n",
    "    languages = ', '.join(languages) if languages else pd.NA\n",
    "\n",
    "    productions = []\n",
    "    try:\n",
    "        prods = WebDriverWait(details, 2).until(lambda x: x.find_elements(By.XPATH, './/li[@data-testid=\"title-details-companies\"]//ul//a'))\n",
    "        for p in prods:\n",
    "            productions.append(p.get_attribute('innerHTML'))\n",
    "    except exceptions.TimeoutException:\n",
    "        pass\n",
    "    productions = ', '.join(productions) if productions else pd.NA\n",
    "\n",
    "    driver.close()\n",
    "    return [title, years, certification, runtime, rating, votes, emmys, creators, actors, genres, origins, languages, productions, url]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Code Explanation and Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script automates the process of scraping links to TV series and miniseries from IMDb's \"Top Rated\" section. \n",
    "\n",
    "**Key Components:**\n",
    "| **Component**             | **Description**                                                                                      |\n",
    "|----------------------------|------------------------------------------------------------------------------------------------------|\n",
    "| **CHROMEDRIVER_PATH**      | Specifies the path to the ChromeDriver executable needed for Selenium to control the Chrome browser. |\n",
    "| **Base URL**               | IMDb URL configured to display TV series and miniseries sorted by user rating.                      |\n",
    "| **Driver Setup**           | Initializes the Selenium WebDriver with the specified ChromeDriver service.                         |\n",
    "| **Navigating the Base URL**| Accesses the IMDb base URL using the WebDriver.                                                     |\n",
    "| **Handling \"Load More\" Button** | A loop that clicks the \"Load More\" button to reveal additional results. Handles exceptions for visibility and element presence. |\n",
    "| **Extracting Product Links** | Uses the `get_links()` function to extract and store all product URLs from the page.               |\n",
    "| **Saving Links to File**   | Writes the scraped URLs into a text file named `links.txt`.                                         |\n",
    "| **Driver Closure**         | Closes the browser session once the scraping process is complete.                                   |\n",
    "\n",
    "**Output:**\n",
    "- A text file named `links.txt` containing all the scraped URLs.\n",
    "\n",
    "**Code Behavior:**\n",
    "- **Dynamic Loading**: Ensures all items are loaded before scraping.\n",
    "- **Resilience**: Handles exceptions related to element visibility and interaction.\n",
    "- **Efficiency**: Captures all relevant URLs in a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMEDRIVER_PATH = '/usr/local/bin/chromedriver'\n",
    "base = 'https://www.imdb.com/search/title/?title_type=tv_series,tv_miniseries&num_votes=25000,&sort=user_rating,desc'\n",
    "service = Service(executable_path=CHROMEDRIVER_PATH)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver.get(base)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        button = driver.find_element(By.XPATH, '//button[@class=\"ipc-btn ipc-btn--single-padding ipc-btn--center-align-content ipc-btn--default-height ipc-btn--core-base ipc-btn--theme-base ipc-btn--button-radius ipc-btn--on-accent2 ipc-text-button ipc-see-more__button\"]')\n",
    "        button.click()\n",
    "    except exceptions.ElementClickInterceptedException:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "    except exceptions.NoSuchElementException:\n",
    "        break\n",
    "\n",
    "    time.sleep(1.5)\n",
    "products = driver.find_elements(By.XPATH, value='//li[@class=\"ipc-metadata-list-summary-item\"]')\n",
    "links = get_links(products)\n",
    "print(len(links))\n",
    "\n",
    "with open('links.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(links))\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Adding Multiprocessing and Saving Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scraping the links, we want to use multiprocessing to parallelize the task of gathering detailed information about each TV show, and then store the results in a CSV file.\n",
    "\n",
    "**Key Components:**\n",
    "| **Component**               | **Description**                                                                                     |\n",
    "|-----------------------------|-----------------------------------------------------------------------------------------------------|\n",
    "| **Multiprocessing**          | Creates a pool of processes to gather detailed information for each link in the `links` list.       |\n",
    "| **get_shows_info**           | A function that fetches detailed information for each TV show from the scraped links.               |\n",
    "| **DataFrame**                | Uses `pandas` to store the detailed information into a DataFrame.                                    |\n",
    "| **CSV File Output**          | Saves the DataFrame to a CSV file named `tvshows_raw.csv`.                                       |\n",
    "\n",
    "**Workflow Explanation:**\n",
    "1. **Setting Up CPU Cores**:\n",
    "   - The number of CPU cores to be used for multiprocessing is determined. Here, the script uses half of the available CPU cores.\n",
    "2. **Creating a Pool of Processes**:\n",
    "   - A `multiprocessing.Pool` is used to create a pool of processes, each of which calls the `get_shows_info()` function to fetch detailed information for each link in the `links` list.\n",
    "3. **Gathering Detailed Information**:\n",
    "   - Each process will fetch detailed information about a TV show, including attributes like title, year of release, certification, runtime, rating, number of votes, and more.\n",
    "4. **Storing Results in a DataFrame**:\n",
    "   - After gathering the information, the results are stored in a `pandas` DataFrame.\n",
    "5. **Saving Results to CSV**:\n",
    "   - The DataFrame is saved to a CSV file named `tvshows_raw.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    coresNr = multiprocessing.cpu_count() // 2\n",
    "    with Pool(coresNr) as p:\n",
    "        results = p.map(get_shows_info, links)\n",
    "        tvshows = [result for result in results]\n",
    "    df = pd.DataFrame(tvshows, columns=['Title', 'Years', 'Certification', 'Runtime', 'Rating', 'Number of Votes', 'Emmys', 'Creators', 'Actors', 'Genres', 'Countries of origins', 'Languages', 'Production companies', 'Link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tvshows_raw.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
